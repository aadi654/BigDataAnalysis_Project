{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/adityadeshpande/Desktop/others/Big Data Project/data 2.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Drop missing rows for critical fields\n",
    "df_clean = df.dropna(subset=['CustomerID', 'Description'])\n",
    "\n",
    "# Remove negative and zero values for Quantity and UnitPrice\n",
    "df_clean = df_clean[(df_clean['Quantity'] > 0) & (df_clean['UnitPrice'] > 0)]\n",
    "\n",
    "# Create TotalRevenue\n",
    "df_clean['TotalRevenue'] = df_clean['Quantity'] * df_clean['UnitPrice']\n",
    "\n",
    "# Drop irrelevant features\n",
    "df_model = df_clean.drop(columns=['InvoiceNo', 'StockCode', 'Description', 'InvoiceDate'])\n",
    "\n",
    "# Aggregate by CustomerID\n",
    "customer_agg = df_model.groupby('CustomerID').agg({\n",
    "    'Quantity': 'sum',\n",
    "    'UnitPrice': 'mean',\n",
    "    'TotalRevenue': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Apply scaling\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(customer_agg[['Quantity', 'UnitPrice', 'TotalRevenue']])\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=['Quantity_scaled', 'UnitPrice_scaled', 'TotalRevenue_scaled'])\n",
    "scaled_df['CustomerID'] = customer_agg['CustomerID'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure InvoiceDate is in datetime\n",
    "df_clean['InvoiceDate'] = pd.to_datetime(df_clean['InvoiceDate'], errors='coerce')\n",
    "\n",
    "# 1. Total Revenue over time\n",
    "revenue_over_time = df_clean.groupby(df_clean['InvoiceDate'].dt.date)['TotalRevenue'].sum()\n",
    "\n",
    "# 2. Top 10 Products by Total Revenue\n",
    "top_products = df_clean.groupby('Description')['TotalRevenue'].sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "# 3. Top Returned Products (Quantity < 0)\n",
    "returned_products = df[df['Quantity'] < 0].groupby('Description')['Quantity'].sum().sort_values().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Total Revenue over Time\n",
    "plt.figure(figsize=(12, 6))\n",
    "revenue_over_time.plot()\n",
    "plt.title('Total Revenue Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Revenue')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Top 10 Products by Total Revenue\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_products.values, y=top_products.index, palette=\"viridis\")\n",
    "plt.title('Top 10 Products by Total Revenue')\n",
    "plt.xlabel('Total Revenue')\n",
    "plt.ylabel('Product')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Top 10 Returned Products\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=returned_products.values, y=returned_products.index, palette=\"mako\")\n",
    "plt.title('Top 10 Most Returned Products')\n",
    "plt.xlabel('Quantity Returned')\n",
    "plt.ylabel('Product')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the customer-level aggregated dataset\n",
    "customer_agg = df_clean.groupby('CustomerID').agg({\n",
    "    'Quantity': 'sum',\n",
    "    'UnitPrice': 'mean',\n",
    "    'TotalRevenue': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Define features and target\n",
    "X = customer_agg[['Quantity', 'UnitPrice']]\n",
    "y = customer_agg['TotalRevenue']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[name] = {\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),  # updated line for older sklearn\n",
    "        \"R2 Score\": r2_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "# Store results in DataFrame\n",
    "results_df = pd.DataFrame(results).T.reset_index().rename(columns={\"index\": \"Model\"})\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Polynomial Linear Regression (degree 2)\n",
    "poly_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "poly_model.fit(X_train, y_train)\n",
    "y_pred_poly = poly_model.predict(X_test)\n",
    "\n",
    "poly_results = {\n",
    "    \"Model\": \"Polynomial Regression (deg=2)\",\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_poly)),\n",
    "    \"R2 Score\": r2_score(y_test, y_pred_poly)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Hyperparameter grid\n",
    "dt_params = {\n",
    "    'max_depth': [3, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Grid search with CV\n",
    "dt_grid = GridSearchCV(DecisionTreeRegressor(random_state=42), dt_params, cv=5, scoring='neg_mean_squared_error')\n",
    "dt_grid.fit(X_train, y_train)\n",
    "y_pred_dt = dt_grid.predict(X_test)\n",
    "\n",
    "dt_results = {\n",
    "    \"Model\": \"Tuned Decision Tree\",\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_dt)),\n",
    "    \"R2 Score\": r2_score(y_test, y_pred_dt)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Grid search with CV\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(random_state=42), rf_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "y_pred_rf = rf_grid.predict(X_test)\n",
    "\n",
    "rf_results = {\n",
    "    \"Model\": \"Tuned Random Forest\",\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_rf)),\n",
    "    \"R2 Score\": r2_score(y_test, y_pred_rf)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "refined_models_df = pd.DataFrame([\n",
    "    poly_results,\n",
    "    dt_results,\n",
    "    rf_results,\n",
    "])\n",
    "\n",
    "refined_models_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load and clean dataset\n",
    "\n",
    "df_clean = df.dropna(subset=['CustomerID', 'Description'])\n",
    "df_clean = df_clean[(df_clean['Quantity'] > 0) & (df_clean['UnitPrice'] > 0)]\n",
    "df_clean['TotalRevenue'] = df_clean['Quantity'] * df_clean['UnitPrice']\n",
    "\n",
    "# Aggregate by CustomerID\n",
    "customer_agg = df_clean.groupby('CustomerID').agg({\n",
    "    'Quantity': 'sum',\n",
    "    'UnitPrice': 'mean',\n",
    "    'TotalRevenue': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Feature engineering\n",
    "customer_agg['AvgRevenuePerItem'] = customer_agg['TotalRevenue'] / customer_agg['Quantity']\n",
    "customer_agg['LogQuantity'] = np.log1p(customer_agg['Quantity'])\n",
    "customer_agg['LogRevenue'] = np.log1p(customer_agg['TotalRevenue'])\n",
    "customer_agg['RevenuePerUnitPrice'] = customer_agg['TotalRevenue'] / customer_agg['UnitPrice']\n",
    "\n",
    "# Define features and target\n",
    "X = customer_agg[['LogQuantity', 'UnitPrice', 'AvgRevenuePerItem', 'RevenuePerUnitPrice']]\n",
    "y = customer_agg['LogRevenue']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Polynomial Regression (degree=3, interaction only)\n",
    "poly3_model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=3, interaction_only=True)),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "poly3_model.fit(X_train, y_train)\n",
    "y_pred_poly = poly3_model.predict(X_test)\n",
    "poly_results = {\n",
    "    \"Model\": \"Polynomial Regression (deg=3)\",\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_poly)),\n",
    "    \"R2 Score\": r2_score(y_test, y_pred_poly)\n",
    "}\n",
    "\n",
    "# Tuned Decision Tree with RandomizedSearchCV\n",
    "dt_param_dist = {\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "dt_random_search = RandomizedSearchCV(DecisionTreeRegressor(random_state=42), dt_param_dist, n_iter=20, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "dt_random_search.fit(X_train, y_train)\n",
    "y_pred_dt = dt_random_search.predict(X_test)\n",
    "dt_results = {\n",
    "    \"Model\": \"Tuned Decision Tree\",\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_dt)),\n",
    "    \"R2 Score\": r2_score(y_test, y_pred_dt)\n",
    "}\n",
    "\n",
    "# Tuned Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 15, None],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "rf_search = GridSearchCV(RandomForestRegressor(random_state=42), rf_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "rf_search.fit(X_train, y_train)\n",
    "y_pred_rf = rf_search.predict(X_test)\n",
    "rf_results = {\n",
    "    \"Model\": \"Tuned Random Forest\",\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_rf)),\n",
    "    \"R2 Score\": r2_score(y_test, y_pred_rf)\n",
    "}\n",
    "\n",
    "# Tuned XGBoost\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "xgb_search = GridSearchCV(xgb_model, xgb_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "xgb_search.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_search.predict(X_test)\n",
    "xgb_results = {\n",
    "    \"Model\": \"Tuned XGBoost\",\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_xgb)),\n",
    "    \"R2 Score\": r2_score(y_test, y_pred_xgb)\n",
    "}\n",
    "\n",
    "# Combine all results\n",
    "refined_models_df = pd.DataFrame([\n",
    "    poly_results,\n",
    "    dt_results,\n",
    "    rf_results,\n",
    "    xgb_results\n",
    "])\n",
    "\n",
    "# import ace_tools as tools; tools.display_dataframe_to_user(name=\"Refined Model Comparison\", dataframe=refined_models_df)\n",
    "refined_models_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
